{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness (% non-null values):\n",
      "Name     80.0\n",
      "Email    80.0\n",
      "Age      80.0\n",
      "dtype: float64\n",
      "\n",
      "Email Validity (% with '@'): 100.00%\n",
      "Email Uniqueness (distinct count): 4\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Eve'],\n",
    "    'Email': ['alice@example.com', 'bob@example', 'charlie@example.com', None, 'eve@example.com'],\n",
    "    'Age': [25, 30, None, 22, 28]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Completeness\n",
    "completeness = df.notnull().mean() * 100\n",
    "\n",
    "# Validity for Email (check if contains '@')\n",
    "valid_emails = df['Email'].dropna().apply(lambda x: '@' in x)\n",
    "validity = valid_emails.mean() * 100\n",
    "\n",
    "# Uniqueness of Email\n",
    "uniqueness = df['Email'].nunique(dropna=True)\n",
    "\n",
    "print(f\"Completeness (% non-null values):\\n{completeness}\\n\")\n",
    "print(f\"Email Validity (% with '@'): {validity:.2f}%\")\n",
    "print(f\"Email Uniqueness (distinct count): {uniqueness}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness (Email): 80.00%\n",
      "Validity (Email): 100.00%\n",
      "Uniqueness (Email): 100.00%\n",
      "Overall Data Quality Score: 93.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Eve'],\n",
    "    'Email': ['alice@example.com', 'bob@example', 'charlie@example.com', None, 'eve@example.com'],\n",
    "    'Age': [25, 30, None, 22, 28]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Completeness for Email column\n",
    "completeness_email = df['Email'].notnull().mean() * 100\n",
    "\n",
    "# Validity for Email (contain '@')\n",
    "valid_emails = df['Email'].dropna().apply(lambda x: '@' in x)\n",
    "validity_email = valid_emails.mean() * 100\n",
    "\n",
    "# Uniqueness for Email\n",
    "unique_emails = df['Email'].nunique(dropna=True)\n",
    "total_non_null_emails = df['Email'].notnull().sum()\n",
    "normalized_uniqueness = (unique_emails / total_non_null_emails) * 100 if total_non_null_emails > 0 else 0\n",
    "\n",
    "# Data Quality Score (average)\n",
    "data_quality_score = (completeness_email + validity_email + normalized_uniqueness) / 3\n",
    "\n",
    "print(f\"Completeness (Email): {completeness_email:.2f}%\")\n",
    "print(f\"Validity (Email): {validity_email:.2f}%\")\n",
    "print(f\"Uniqueness (Email): {normalized_uniqueness:.2f}%\")\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: great_expectations in /home/vscode/.local/lib/python3.10/site-packages (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.2.3)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.2.2)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.23.0)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.1.3)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.67.1)\n",
      "Requirement already satisfied: jinja2>=3 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.1.6)\n",
      "Collecting pandas<2.2,>=1.3.0\n",
      "  Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.13.2)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (24.2)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (0.18.10)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.20 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.32.3)\n",
      "Requirement already satisfied: cryptography>=3.2 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (45.0.2)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.11.5)\n",
      "Requirement already satisfied: posthog<4,>3 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.25.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.26.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (1.15.3)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (5.3.1)\n",
      "Requirement already satisfied: toolz in /home/vscode/.local/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (1.0.0)\n",
      "Requirement already satisfied: entrypoints in /home/vscode/.local/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (0.4)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/vscode/.local/lib/python3.10/site-packages (from cryptography>=3.2->great_expectations) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.10/site-packages (from jinja2>=3->great_expectations) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (2025.4.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (25.3.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.25.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas<2.2,>=1.3.0->great_expectations) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas<2.2,>=1.3.0->great_expectations) (2025.2)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.6)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (2.33.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/vscode/.local/lib/python3.10/site-packages (from ruamel.yaml>=0.16->great_expectations) (0.2.12)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.10/site-packages (from cffi>=1.14->cryptography>=3.2->great_expectations) (2.22)\n",
      "Installing collected packages: numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "Successfully installed numpy-1.26.4 pandas-2.1.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install great_expectations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: great_expectations: command not found\n"
     ]
    }
   ],
   "source": [
    "!great_expectations init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: great_expectations: command not found\n"
     ]
    }
   ],
   "source": [
    "!great_expectations suite new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PandasDataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 1: Load CSV with pandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.dataset'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from great_expectations.dataset import PandasDataset\n",
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "# Step 1: Load CSV with pandas\n",
    "df = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/sample_data.csv')\n",
    "\n",
    "# Step 2: Wrap pandas DataFrame as a GE PandasDataset\n",
    "df_ge = PandasDataset(df)\n",
    "\n",
    "# Step 3: Initialize Great Expectations DataContext\n",
    "context = DataContext()\n",
    "\n",
    "# Step 4: Create a new expectation suite\n",
    "suite_name = \"basic_suite\"\n",
    "suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Step 5: Add completeness expectations for columns\n",
    "for column in ['Name', 'Email', 'Age']:\n",
    "    suite.add_expectation(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": column},\n",
    "    )\n",
    "\n",
    "# Step 6: Save the expectation suite\n",
    "context.save_expectation_suite(suite, suite_name)\n",
    "\n",
    "# Step 7: Validate the data against the suite\n",
    "results = df_ge.validate(expectation_suite=suite)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'run_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the checkpoint\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m checkpoint_result \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_checkpoint\u001b[49m(checkpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'run_checkpoint'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "from great_expectations.checkpoint import Checkpoint\n",
    "from great_expectations.data_context import get_context\n",
    "\n",
    "# Get the context\n",
    "context = get_context()\n",
    "\n",
    "# Run the checkpoint\n",
    "checkpoint_result = context.run_checkpoint(checkpoint_name=\"my_checkpoint\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'run_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Run script\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mrun_checkpoint_and_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_checkpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m, in \u001b[0;36mrun_checkpoint_and_score\u001b[0;34m(checkpoint_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_checkpoint_and_score\u001b[39m(checkpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Load context and run checkpoint\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[0;32m---> 27\u001b[0m     checkpoint_result \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_checkpoint\u001b[49m(checkpoint_name\u001b[38;5;241m=\u001b[39mcheckpoint_name)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Convert result to dict\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     result_dict \u001b[38;5;241m=\u001b[39m checkpoint_result\u001b[38;5;241m.\u001b[39mto_json_dict()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'run_checkpoint'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import json\n",
    "from great_expectations.data_context import get_context\n",
    "\n",
    "def calculate_data_quality_score(result):\n",
    "    \"\"\"\n",
    "    Calculate data quality score from validation results.\n",
    "    Returns score as percentage of successful expectations.\n",
    "    \"\"\"\n",
    "    success_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for validation in result[\"run_results\"].values():\n",
    "        expectations = validation[\"validation_result\"][\"results\"]\n",
    "        for expectation in expectations:\n",
    "            total_count += 1\n",
    "            if expectation[\"success\"]:\n",
    "                success_count += 1\n",
    "\n",
    "    if total_count == 0:\n",
    "        return 0.0\n",
    "    return (success_count / total_count) * 100\n",
    "\n",
    "def run_checkpoint_and_score(checkpoint_name=\"my_checkpoint\"):\n",
    "    # Load context and run checkpoint\n",
    "    context = get_context()\n",
    "    checkpoint_result = context.run_checkpoint(checkpoint_name=checkpoint_name)\n",
    "\n",
    "    # Convert result to dict\n",
    "    result_dict = checkpoint_result.to_json_dict()\n",
    "\n",
    "    # Calculate data quality score\n",
    "    score = calculate_data_quality_score(result_dict)\n",
    "\n",
    "    print(f\"✅ Data Quality Score: {score:.2f}%\")\n",
    "\n",
    "    # Optional: save result to JSON\n",
    "    with open(\"data_quality_result.json\", \"w\") as f:\n",
    "        json.dump(result_dict, f, indent=2)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Run script\n",
    "if __name__ == \"__main__\":\n",
    "    run_checkpoint_and_score(\"my_checkpoint\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Action' from 'great_expectations.checkpoint.actions' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/checkpoint/actions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Action\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTriggerCleaningAction\u001b[39;00m(Action):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Action' from 'great_expectations.checkpoint.actions' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/checkpoint/actions.py)"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "from great_expectations.checkpoint.actions import Action\n",
    "import subprocess\n",
    "\n",
    "class TriggerCleaningAction(Action):\n",
    "    def __init__(self, threshold: float = 90.0, cleaning_script: str = \"clean_data.py\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.cleaning_script = cleaning_script\n",
    "\n",
    "    def run(self, validation_result_suite, **kwargs):\n",
    "        total = len(validation_result_suite[\"results\"])\n",
    "        passed = sum(1 for r in validation_result_suite[\"results\"] if r[\"success\"])\n",
    "        score = (passed / total) * 100 if total > 0 else 0\n",
    "\n",
    "        print(f\"📊 Data Quality Score: {score:.2f}%\")\n",
    "        if score < self.threshold:\n",
    "            print(\"⚠️ Quality score below threshold — triggering data cleaning.\")\n",
    "            subprocess.run([\"python\", self.cleaning_script])\n",
    "        else:\n",
    "            print(\"✅ Data quality acceptable — no cleaning required.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
