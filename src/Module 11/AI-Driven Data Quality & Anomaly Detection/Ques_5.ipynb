{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Deduplication using Clustering\n",
    "**Objective**: Learn and implement data deduplication techniques.\n",
    "\n",
    "**Task**: Hierarchical Clustering for Deduplication\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Obtain a dataset containing duplicate employee information.\n",
    "2. Perform Clustering: Use hierarchical agglomerative clustering to cluster the employee\n",
    "records.\n",
    "3. Evaluate Duplicates: Determine duplicates by analyzing the clusters formed.\n",
    "4. Clean Data: Remove duplicate employee records found during clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "    EmployeeID           Name                      Email       Department  \\\n",
      "0          101       John Doe       john.doe@example.com               HR   \n",
      "1          102     Jane Smith     jane.smith@example.com            Sales   \n",
      "2          103    Peter Jones    peter.jones@example.com               IT   \n",
      "3          104    Alice Brown    alice.brown@example.com        Marketing   \n",
      "4          105   Robert White   robert.white@example.com          Finance   \n",
      "5          106        Jon Doe          j.doe@example.com  Human Resources   \n",
      "6          107     Jane Smyth     jane.smyth@example.com            Sales   \n",
      "7          108    Peter Jonez        p.jones@example.com               IT   \n",
      "8          109   Alice Browne        alice.b@example.com        Marketing   \n",
      "9          110      Rob White      rob.white@example.com          Finance   \n",
      "10         111  Johnathan Doe  johnathan.doe@example.com               HR   \n",
      "\n",
      "           Phone  \n",
      "0   111-222-3333  \n",
      "1   222-333-4444  \n",
      "2   333-444-5555  \n",
      "3   444-555-6666  \n",
      "4   555-666-7777  \n",
      "5   111-222-3333  \n",
      "6   222-333-4444  \n",
      "7   333-444-5555  \n",
      "8   444-555-6666  \n",
      "9   555-666-7777  \n",
      "10  111-222-3334  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Dataset with Cluster IDs:\n",
      "    EmployeeID           Name                      Email  ClusterID\n",
      "0          101       John Doe       john.doe@example.com          1\n",
      "1          102     Jane Smith     jane.smith@example.com          7\n",
      "2          103    Peter Jones    peter.jones@example.com          4\n",
      "3          104    Alice Brown    alice.brown@example.com          5\n",
      "4          105   Robert White   robert.white@example.com          9\n",
      "5          106        Jon Doe          j.doe@example.com          2\n",
      "6          107     Jane Smyth     jane.smyth@example.com          8\n",
      "7          108    Peter Jonez        p.jones@example.com          4\n",
      "8          109   Alice Browne        alice.b@example.com          6\n",
      "9          110      Rob White      rob.white@example.com         10\n",
      "10         111  Johnathan Doe  johnathan.doe@example.com          3\n",
      "\n",
      "==================================================\n",
      "\n",
      "Identified Duplicate Records (within clusters of size > 1):\n",
      "   EmployeeID         Name                    Email  ClusterID\n",
      "2         103  Peter Jones  peter.jones@example.com          4\n",
      "7         108  Peter Jonez      p.jones@example.com          4\n",
      "\n",
      "==================================================\n",
      "\n",
      "Cleaned Dataset (Duplicates Removed):\n",
      "   EmployeeID           Name                      Email       Department  \\\n",
      "0         101       John Doe       john.doe@example.com               HR   \n",
      "1         106        Jon Doe          j.doe@example.com  Human Resources   \n",
      "2         111  Johnathan Doe  johnathan.doe@example.com               HR   \n",
      "3         103    Peter Jones    peter.jones@example.com               IT   \n",
      "4         104    Alice Brown    alice.brown@example.com        Marketing   \n",
      "5         109   Alice Browne        alice.b@example.com        Marketing   \n",
      "6         102     Jane Smith     jane.smith@example.com            Sales   \n",
      "7         107     Jane Smyth     jane.smyth@example.com            Sales   \n",
      "8         105   Robert White   robert.white@example.com          Finance   \n",
      "9         110      Rob White      rob.white@example.com          Finance   \n",
      "\n",
      "          Phone  \n",
      "0  111-222-3333  \n",
      "1  111-222-3333  \n",
      "2  111-222-3334  \n",
      "3  333-444-5555  \n",
      "4  444-555-6666  \n",
      "5  444-555-6666  \n",
      "6  222-333-4444  \n",
      "7  222-333-4444  \n",
      "8  555-666-7777  \n",
      "9  555-666-7777  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Verification of Cleaned Data:\n",
      "Warning: 'John Doe' and 'Jon Doe' still present in cleaned data. Threshold might need adjustment.\n",
      "Warning: 'Jane Smith' and 'Jane Smyth' still present in cleaned data. Threshold might need adjustment.\n",
      "'Peter Jones' or 'Peter Jonez' (one of the pair) is present, which is expected.\n",
      "Warning: 'Alice Brown' and 'Alice Browne' still present in cleaned data. Threshold might need adjustment.\n",
      "Warning: 'Robert White' and 'Rob White' still present in cleaned data. Threshold might need adjustment.\n",
      "\n",
      "Records that were removed as duplicates:\n",
      "   EmployeeID         Name                Email  ClusterID\n",
      "7         108  Peter Jonez  p.jones@example.com          4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2552/2854009314.py:65: ClusterWarning: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linked = linkage(distance_matrix, method='ward')\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Data Set - Create a sample dataset with duplicate employee information\n",
    "# We'll introduce some variations to simulate real-world duplicates (e.g., typos, different formats)\n",
    "data = {\n",
    "    'EmployeeID': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
    "    'Name': [\n",
    "        'John Doe', 'Jane Smith', 'Peter Jones', 'Alice Brown', 'Robert White',\n",
    "        'Jon Doe', 'Jane Smyth', 'Peter Jonez', 'Alice Browne', 'Rob White',\n",
    "        'Johnathan Doe' # A slightly different name, not a direct duplicate\n",
    "    ],\n",
    "    'Email': [\n",
    "        'john.doe@example.com', 'jane.smith@example.com', 'peter.jones@example.com',\n",
    "        'alice.brown@example.com', 'robert.white@example.com',\n",
    "        'j.doe@example.com', 'jane.smyth@example.com', 'p.jones@example.com',\n",
    "        'alice.b@example.com', 'rob.white@example.com',\n",
    "        'johnathan.doe@example.com'\n",
    "    ],\n",
    "    'Department': [\n",
    "        'HR', 'Sales', 'IT', 'Marketing', 'Finance',\n",
    "        'Human Resources', 'Sales', 'IT', 'Marketing', 'Finance',\n",
    "        'HR'\n",
    "    ],\n",
    "    'Phone': [\n",
    "        '111-222-3333', '222-333-4444', '333-444-5555', '444-555-6666',\n",
    "        '555-666-7777', '111-222-3333', '222-333-4444', '333-444-5555',\n",
    "        '444-555-6666', '555-666-7777', '111-222-3334'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset:\")\n",
    "print(df)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# For deduplication, we'll focus on 'Name' and 'Email' as primary identifiers.\n",
    "# We'll concatenate them to create a single string representation for each record.\n",
    "df['Combined_Info'] = df['Name'].str.lower() + \" \" + df['Email'].str.lower()\n",
    "\n",
    "# Step 2: Perform Clustering - Use hierarchical agglomerative clustering\n",
    "# 2.1 Feature Extraction: Convert text data into numerical features using TF-IDF\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency) is suitable for text similarity.\n",
    "vectorizer = TfidfVectorizer().fit_transform(df['Combined_Info'])\n",
    "\n",
    "# 2.2 Calculate Similarity Matrix: Compute cosine similarity between records\n",
    "# Cosine similarity measures the cosine of the angle between two non-zero vectors.\n",
    "# A value closer to 1 indicates higher similarity.\n",
    "similarity_matrix = cosine_similarity(vectorizer)\n",
    "\n",
    "# Convert similarity to distance for hierarchical clustering\n",
    "# Distance = 1 - Similarity. This way, higher similarity means lower distance.\n",
    "distance_matrix = 1 - similarity_matrix\n",
    "\n",
    "# Ensure the distance matrix is symmetric and has zeros on the diagonal\n",
    "# (though cosine_similarity and 1-x will naturally do this for self-comparison)\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "\n",
    "# Perform hierarchical clustering using 'ward' linkage\n",
    "# 'ward' minimizes the variance of the clusters being merged.\n",
    "# It's generally good for creating compact, spherical clusters.\n",
    "linked = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 3: Evaluate Duplicates - Determine duplicates by analyzing the clusters formed.\n",
    "# We need to choose a threshold to cut the dendrogram and form clusters.\n",
    "# A smaller threshold means more clusters (less aggressive deduplication).\n",
    "# A larger threshold means fewer clusters (more aggressive deduplication).\n",
    "# For this example, let's choose a threshold that groups records with high similarity.\n",
    "# A common approach is to inspect the dendrogram or try different thresholds.\n",
    "# Let's start with a threshold of 0.5 (meaning records with a distance less than 0.5 are grouped).\n",
    "# This corresponds to a similarity of 0.5 or more.\n",
    "threshold = 0.5 # Adjust this value based on desired strictness of deduplication\n",
    "\n",
    "# fcluster forms flat clusters from the hierarchical clustering defined by 'linked'.\n",
    "# 'criterion='distance'' means clusters are formed when the distance between them is below 'threshold'.\n",
    "clusters = fcluster(linked, threshold, criterion='distance')\n",
    "\n",
    "# Add cluster IDs to the DataFrame\n",
    "df['ClusterID'] = clusters\n",
    "\n",
    "print(\"Dataset with Cluster IDs:\")\n",
    "print(df[['EmployeeID', 'Name', 'Email', 'ClusterID']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Identify duplicates: Records within the same cluster (and cluster size > 1) are considered duplicates.\n",
    "duplicate_clusters = df.groupby('ClusterID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "print(\"Identified Duplicate Records (within clusters of size > 1):\")\n",
    "print(duplicate_clusters[['EmployeeID', 'Name', 'Email', 'ClusterID']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Step 4: Clean Data - Remove duplicate employee records found during clustering.\n",
    "# For each cluster, we'll keep only one record (e.g., the first one encountered or the one with the lowest EmployeeID).\n",
    "# Here, we'll keep the first record in each cluster.\n",
    "clean_df = df.groupby('ClusterID').first().reset_index()\n",
    "\n",
    "# Drop the 'Combined_Info' column as it was just for internal processing\n",
    "clean_df = clean_df.drop(columns=['Combined_Info'])\n",
    "\n",
    "print(\"Cleaned Dataset (Duplicates Removed):\")\n",
    "print(clean_df[['EmployeeID', 'Name', 'Email', 'Department', 'Phone']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Verification: Check if any of the original duplicates are still present in the cleaned data\n",
    "original_duplicate_pairs = [\n",
    "    ('John Doe', 'Jon Doe'),\n",
    "    ('Jane Smith', 'Jane Smyth'),\n",
    "    ('Peter Jones', 'Peter Jonez'),\n",
    "    ('Alice Brown', 'Alice Browne'),\n",
    "    ('Robert White', 'Rob White')\n",
    "]\n",
    "\n",
    "print(\"Verification of Cleaned Data:\")\n",
    "for name1, name2 in original_duplicate_pairs:\n",
    "    if name1 in clean_df['Name'].values and name2 in clean_df['Name'].values:\n",
    "        print(f\"Warning: '{name1}' and '{name2}' still present in cleaned data. Threshold might need adjustment.\")\n",
    "    elif name1 in clean_df['Name'].values or name2 in clean_df['Name'].values:\n",
    "        print(f\"'{name1}' or '{name2}' (one of the pair) is present, which is expected.\")\n",
    "    else:\n",
    "        print(f\"Neither '{name1}' nor '{name2}' found, indicating successful deduplication for this pair.\")\n",
    "\n",
    "# To see the actual records that were removed:\n",
    "removed_records = df[~df['EmployeeID'].isin(clean_df['EmployeeID'])]\n",
    "print(\"\\nRecords that were removed as duplicates:\")\n",
    "print(removed_records[['EmployeeID', 'Name', 'Email', 'ClusterID']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
