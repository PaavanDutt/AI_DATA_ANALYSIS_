{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "customer_id          0\n",
      "email               10\n",
      "transaction_date    14\n",
      "department          26\n",
      "supplier_name        0\n",
      "product_id           0\n",
      "date_column          0\n",
      "phone                0\n",
      "state                0\n",
      "month                0\n",
      "revenue              0\n",
      "quarter              0\n",
      "engagement_score     0\n",
      "price                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question: Introduction to Missing Data in a DataFrame\n",
    "# Description: Load a simple CSV file into a DataFrame and identify missing values.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Load the data: Use the pandas library to read a CSV file.\n",
    "# 2. Check for missing values: Use the isnull() method to find missing values.\n",
    "# 3. Summarize missing data: Use the sum() function to count the number of missing values in each column.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the data from a CSV file into a DataFrame\n",
    "df = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 3/common_data_errors_example.csv')\n",
    "\n",
    "# Step 2: Check for missing values in the DataFrame\n",
    "missing_values = df.isnull()\n",
    "\n",
    "# Step 3: Summarize the missing data by counting the number of missing values in each column\n",
    "missing_summary = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping rows with missing values:\n",
      "    customer_id               email transaction_date department supplier_name  \\\n",
      "0             1   user1@example.com       2024-07-22         IT    Supplier 0   \n",
      "1             2   user2@example.com       2024-11-26         HR    Supplier 1   \n",
      "2             3   user3@example.com       2024-04-05         HR    Supplier 2   \n",
      "3             4   user4@example.com       2024-12-13         IT    Supplier 3   \n",
      "4             5   user5@example.com       2024-11-15      Sales    Supplier 4   \n",
      "7             8   user8@example.com       2024-05-28      Sales    Supplier 2   \n",
      "8             9   user9@example.com       2024-09-02         HR    Supplier 3   \n",
      "11           12  user12@example.com       2024-09-15         IT    Supplier 1   \n",
      "12           13  user13@example.com       2024-08-04         HR    Supplier 2   \n",
      "14           15  user15@example.com       2024-07-07         IT    Supplier 4   \n",
      "15           16  user16@example.com       2024-08-15      Sales    Supplier 0   \n",
      "18           19  user19@example.com       2024-05-19         HR    Supplier 3   \n",
      "23           24  user24@example.com       2024-12-15      Sales    Supplier 3   \n",
      "24           25  user25@example.com       2024-09-22         IT    Supplier 4   \n",
      "26           27  user27@example.com       2024-10-26         IT    Supplier 1   \n",
      "28           29  user29@example.com       2024-11-22      Sales    Supplier 3   \n",
      "30           31  user31@example.com       2024-10-18         IT    Supplier 0   \n",
      "31           32  user32@example.com       2024-11-19      Sales    Supplier 1   \n",
      "33           34  user34@example.com       2024-10-06         HR    Supplier 3   \n",
      "35           36  user36@example.com       2024-05-06         IT    Supplier 0   \n",
      "36           37  user37@example.com       2024-11-09         IT    Supplier 1   \n",
      "37           38  user38@example.com       2024-04-15      Sales    Supplier 2   \n",
      "40           41  user41@example.com       2024-08-11      Sales    Supplier 0   \n",
      "43           44  user44@example.com       2024-03-28         IT    Supplier 3   \n",
      "44           45  user45@example.com       2024-08-24         HR    Supplier 4   \n",
      "45           46  user46@example.com       2024-08-17         IT    Supplier 0   \n",
      "46           47  user47@example.com       2024-03-13         HR    Supplier 1   \n",
      "47           48  user48@example.com       2024-06-07      Sales    Supplier 2   \n",
      "53           54  user54@example.com       2024-08-28         IT    Supplier 3   \n",
      "54           55  user55@example.com       2024-04-27      Sales    Supplier 4   \n",
      "56           57  user57@example.com       2024-07-28         HR    Supplier 1   \n",
      "60           61  user61@example.com       2024-04-24         HR    Supplier 0   \n",
      "61           62  user62@example.com       2024-11-13         IT    Supplier 1   \n",
      "64           65  user65@example.com       2024-11-18         HR    Supplier 4   \n",
      "65           66  user66@example.com       2024-05-14         IT    Supplier 0   \n",
      "66           67  user67@example.com       2024-10-07         IT    Supplier 1   \n",
      "68           69  user69@example.com       2024-02-14      Sales    Supplier 3   \n",
      "70           71  user71@example.com       2024-07-12      Sales    Supplier 0   \n",
      "71           72  user72@example.com       2024-04-27         IT    Supplier 1   \n",
      "72           73  user73@example.com       2024-02-24         IT    Supplier 2   \n",
      "73           74  user74@example.com       2024-03-04         HR    Supplier 3   \n",
      "75           76  user76@example.com       2024-11-16         HR    Supplier 0   \n",
      "77           78  user78@example.com       2024-08-13         IT    Supplier 2   \n",
      "78           79  user79@example.com       2024-11-18      Sales    Supplier 3   \n",
      "80           81  user81@example.com       2024-03-22      Sales    Supplier 0   \n",
      "81           82  user82@example.com       2024-05-16      Sales    Supplier 1   \n",
      "82           83  user83@example.com       2024-04-24      Sales    Supplier 2   \n",
      "84           85  user85@example.com       2024-10-06         HR    Supplier 4   \n",
      "85           86  user86@example.com       2024-09-18         IT    Supplier 0   \n",
      "87           88  user88@example.com       2024-02-19      Sales    Supplier 2   \n",
      "88           89  user89@example.com       2024-04-21         HR    Supplier 3   \n",
      "91           92  user92@example.com       2024-07-14      Sales    Supplier 1   \n",
      "92           93  user93@example.com       2024-05-11      Sales    Supplier 2   \n",
      "95           96  user96@example.com       2024-09-21         IT    Supplier 0   \n",
      "98           99  user99@example.com       2024-07-15         IT    Supplier 3   \n",
      "\n",
      "   product_id date_column           phone       state month  revenue quarter  \\\n",
      "0          P1  06/23/2024  (555) 123-1000      Calif.   Jun     4174      Q4   \n",
      "1          P2  2024-06-27    555-123-1001      Calif.   Jun     4507      Q4   \n",
      "2          P3  2024-07-05    555-123-1002  California   Jan     1860      Q3   \n",
      "3          P4  06/26/2024    555-123-1003      Calif.   Jan     2294      Q4   \n",
      "4          P5  2024-06-10  (555) 123-1004      Calif.   Feb     2130      Q3   \n",
      "7          P8  2024-07-01    555-123-1007      Calif.   Apr     4092      Q2   \n",
      "8          P9  2024-02-28  (555) 123-1008          CA   Apr     2638      Q1   \n",
      "11        P12  2024-08-21    555-123-1011          CA   Feb     2238      Q4   \n",
      "12        P13  02/01/2024  (555) 123-1012  California   Jan     1330      Q2   \n",
      "14        P15  2024-03-21    555-123-1014      Calif.   Jun     3135      Q1   \n",
      "15        P16  10/17/2024    555-123-1015      Calif.   Feb     4444      Q4   \n",
      "18        P19  08/03/2024    555-123-1018  California   Jan     4735      Q3   \n",
      "23         P4  2024-09-22    555-123-1023  California   May     3391      Q2   \n",
      "24         P5  06/04/2024  (555) 123-1024      Calif.   Apr     2515      Q1   \n",
      "26         P7  2024-07-23    555-123-1026      Calif.   Mar     3853      Q1   \n",
      "28         P9  2024-11-08  (555) 123-1028      Calif.   Mar     2215      Q4   \n",
      "30        P11  10/18/2024    555-123-1030          CA   Feb     3324      Q2   \n",
      "31        P12  2024-11-08    555-123-1031      Calif.   Jun     2184      Q2   \n",
      "33        P14  07/04/2024    555-123-1033      Calif.   Jun     4385      Q4   \n",
      "35        P16  2024-10-24    555-123-1035          CA   Apr     3300      Q4   \n",
      "36        P17  08/01/2024  (555) 123-1036          CA   Jan     1747      Q3   \n",
      "37        P18  2024-10-03    555-123-1037  California   Apr     3904      Q2   \n",
      "40         P1  2024-06-19  (555) 123-1040          CA   Apr     2082      Q1   \n",
      "43         P4  2024-11-27    555-123-1043      Calif.   Mar     3047      Q1   \n",
      "44         P5  2024-02-16  (555) 123-1044      Calif.   Jan     4547      Q4   \n",
      "45         P6  06/06/2024    555-123-1045          CA   Feb     3747      Q2   \n",
      "46         P7  2024-12-27    555-123-1046          CA   Apr     1975      Q4   \n",
      "47         P8  2024-03-04    555-123-1047      Calif.   Apr     2806      Q2   \n",
      "53        P14  2024-05-10    555-123-1053      Calif.   Jun     2899      Q4   \n",
      "54        P15  04/07/2024    555-123-1054      Calif.   May     4638      Q4   \n",
      "56        P17  2024-05-05  (555) 123-1056          CA   Jun     3879      Q1   \n",
      "60         P1  03/03/2024  (555) 123-1060          CA   Feb     4890      Q4   \n",
      "61         P2  2024-06-26    555-123-1061      Calif.   Mar     1646      Q1   \n",
      "64         P5  2024-04-12  (555) 123-1064      Calif.   Apr     3214      Q3   \n",
      "65         P6  2024-02-07    555-123-1065  California   Jun     2297      Q2   \n",
      "66         P7  04/26/2024    555-123-1066  California   Jun     3435      Q3   \n",
      "68         P9  2024-08-09  (555) 123-1068          CA   Feb     3363      Q4   \n",
      "70        P11  2024-09-18    555-123-1070          CA   Mar     1241      Q4   \n",
      "71        P12  2024-11-20    555-123-1071  California   Mar     3041      Q2   \n",
      "72        P13  03/11/2024  (555) 123-1072  California   May     3824      Q1   \n",
      "73        P14  2024-08-06    555-123-1073          CA   May     4417      Q4   \n",
      "75        P16  05/16/2024    555-123-1075      Calif.   Apr     3945      Q3   \n",
      "77        P18  2024-01-03    555-123-1077          CA   Apr     3139      Q3   \n",
      "78        P19  12/25/2024    555-123-1078          CA   Feb     2390      Q4   \n",
      "80         P1  2024-06-19  (555) 123-1080  California   Mar     2478      Q3   \n",
      "81         P2  02/24/2024    555-123-1081  California   Jun     4499      Q3   \n",
      "82         P3  2024-11-08    555-123-1082  California   Mar     3556      Q4   \n",
      "84         P5  03/09/2024  (555) 123-1084      Calif.   Feb     1034      Q3   \n",
      "85         P6  2024-07-15    555-123-1085  California   May     3253      Q3   \n",
      "87         P8  08/04/2024    555-123-1087  California   Feb     2955      Q2   \n",
      "88         P9  2024-12-17  (555) 123-1088  California   Mar     2585      Q4   \n",
      "91        P12  2024-02-25    555-123-1091      Calif.   Jan     4073      Q4   \n",
      "92        P13  2024-08-27  (555) 123-1092      Calif.   Mar     2021      Q4   \n",
      "95        P16  2024-12-01    555-123-1095      Calif.   Jan     2129      Q4   \n",
      "98        P19  2024-05-21    555-123-1098      Calif.   Feb     2500      Q1   \n",
      "\n",
      "    engagement_score       price  \n",
      "0           0.842285  320.832159  \n",
      "1           0.449754  343.545671  \n",
      "2           0.395150  270.157946  \n",
      "3           0.926659  229.413751  \n",
      "4           0.727272  280.917614  \n",
      "7           0.520834  191.130683  \n",
      "8           0.961172  128.658370  \n",
      "11          0.539692  491.877339  \n",
      "12          0.586751  205.423977  \n",
      "14          0.607034  401.189111  \n",
      "15          0.275999   83.851597  \n",
      "18          0.015636  430.595814  \n",
      "23          0.198842  180.846334  \n",
      "24          0.711342   57.126510  \n",
      "26          0.605960  204.810290  \n",
      "28          0.651077  420.477952  \n",
      "30          0.850039  370.255898  \n",
      "31          0.449451  112.445094  \n",
      "33          0.370818  350.934356  \n",
      "35          0.665922   95.727914  \n",
      "36          0.591298  491.262488  \n",
      "37          0.274722  263.151587  \n",
      "40          0.971712  483.055482  \n",
      "43          0.235985  102.466483  \n",
      "44          0.256068  146.646963  \n",
      "45          0.040434  353.175337  \n",
      "46          0.710663  424.863960  \n",
      "47          0.110891  429.598903  \n",
      "53          0.695516  337.804245  \n",
      "54          0.139331  294.536445  \n",
      "56          0.539841  470.665387  \n",
      "60          0.694785  247.950739  \n",
      "61          0.880468  229.727830  \n",
      "64          0.105494   18.856928  \n",
      "65          0.456535  252.007920  \n",
      "66          0.218440   97.623128  \n",
      "68          0.883280  374.643556  \n",
      "70          0.122088  160.949788  \n",
      "71          0.356298  275.844713  \n",
      "72          0.906828  259.318898  \n",
      "73          0.272132  321.802983  \n",
      "75          0.000520  299.036715  \n",
      "77          0.304781  248.503655  \n",
      "78          0.164656  453.988406  \n",
      "80          0.484830  181.538420  \n",
      "81          0.692436  326.100647  \n",
      "82          0.269412  337.772789  \n",
      "84          0.168291  122.790781  \n",
      "85          0.218764  254.604756  \n",
      "87          0.403836  386.591467  \n",
      "88          0.064892   31.365848  \n",
      "91          0.696304  146.984567  \n",
      "92          0.712271  442.912071  \n",
      "95          0.266781  172.067649  \n",
      "98          0.033051  490.362476  \n"
     ]
    }
   ],
   "source": [
    "# Question: Dropping Rows with Missing Values\n",
    "# Description: Practice the deletion method by removing rows with any missing values from a dataset.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Use dropna() method: Use the dropna() method to remove rows with missing values.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 3/common_data_errors_example.csv')\n",
    "\n",
    "# Drop rows that contain any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"DataFrame after dropping rows with missing values:\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping columns with missing values:\n",
      "    customer_id supplier_name product_id date_column           phone  \\\n",
      "0             1    Supplier 0         P1  06/23/2024  (555) 123-1000   \n",
      "1             2    Supplier 1         P2  2024-06-27    555-123-1001   \n",
      "2             3    Supplier 2         P3  2024-07-05    555-123-1002   \n",
      "3             4    Supplier 3         P4  06/26/2024    555-123-1003   \n",
      "4             5    Supplier 4         P5  2024-06-10  (555) 123-1004   \n",
      "..          ...           ...        ...         ...             ...   \n",
      "95           96    Supplier 0        P16  2024-12-01    555-123-1095   \n",
      "96           97    Supplier 1        P17  06/12/2024  (555) 123-1096   \n",
      "97           98    Supplier 2        P18  2024-12-17    555-123-1097   \n",
      "98           99    Supplier 3        P19  2024-05-21    555-123-1098   \n",
      "99          100    Supplier 4        P20  05/23/2024    555-123-1099   \n",
      "\n",
      "         state month  revenue quarter  engagement_score       price  \n",
      "0       Calif.   Jun     4174      Q4          0.842285  320.832159  \n",
      "1       Calif.   Jun     4507      Q4          0.449754  343.545671  \n",
      "2   California   Jan     1860      Q3          0.395150  270.157946  \n",
      "3       Calif.   Jan     2294      Q4          0.926659  229.413751  \n",
      "4       Calif.   Feb     2130      Q3          0.727272  280.917614  \n",
      "..         ...   ...      ...     ...               ...         ...  \n",
      "95      Calif.   Jan     2129      Q4          0.266781  172.067649  \n",
      "96      Calif.   May     4843      Q1          0.976615  280.854834  \n",
      "97      Calif.   May     4893      Q1          0.411037  290.423310  \n",
      "98      Calif.   Feb     2500      Q1          0.033051  490.362476  \n",
      "99      Calif.   Apr     1702      Q3          0.345071   46.919665  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question: Dropping Columns with Missing Values\n",
    "# Description: Practice deleting entire columns that contain missing values.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Use dropna() with axis parameter: Set axis=1 in dropna() to remove columns with missing values.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 3/common_data_errors_example.csv')\n",
    "\n",
    "# Drop columns that contain any missing values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "print(\"DataFrame after dropping columns with missing values:\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after mean imputation on 'Sales' column:\n",
      "   employee_id             name   age department        salary  \\\n",
      "0            1         John Doe  28.0      Sales  55000.000000   \n",
      "1            2       Jane Smith  34.0        NaN  62000.000000   \n",
      "2            3      Bob Johnson   NaN  Marketing  58000.000000   \n",
      "3            4   Alice Williams  29.0  Marketing  62666.666667   \n",
      "4            5      Chris Evans  45.0      Sales  70000.000000   \n",
      "5            6      Emily Davis  38.0         HR  67000.000000   \n",
      "6            7              NaN  41.0         HR  65000.000000   \n",
      "7            8       Mary Clark  30.0      Sales  59000.000000   \n",
      "8            9      James Lewis  37.0        NaN  62000.000000   \n",
      "9           10  Patricia Taylor  32.0         HR  66000.000000   \n",
      "\n",
      "                         email  \n",
      "0         john.doe@example.com  \n",
      "1       jane.smith@example.com  \n",
      "2      bob.johnson@example.com  \n",
      "3   alice.williams@example.com  \n",
      "4                          NaN  \n",
      "5      emily.davis@example.com  \n",
      "6    michael.brown@example.com  \n",
      "7       mary.clark@example.com  \n",
      "8      james.lewis@example.com  \n",
      "9  patricia.taylor@example.com  \n"
     ]
    }
   ],
   "source": [
    "# Question: Mean Imputation for Numerical Data\n",
    "# Description: Fill missing values in a numerical column with the mean of that column.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate mean and fill NA: Use mean() to calculate and fillna() to fill the missing values.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 3/Techniques to Improve Data Quality/employees.csv')\n",
    "\n",
    "# Calculate the mean of the numerical column 'Sales'\n",
    "mean_value = df['salary'].mean()\n",
    "\n",
    "# Fill missing values in the 'Sales' column with the mean value\n",
    "df['salary'].fillna(mean_value, inplace=True)\n",
    "\n",
    "print(\"DataFrame after mean imputation on 'Sales' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sales', 'customer_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'department' before imputation: 2\n",
      "Mode of 'department': HR\n",
      "\n",
      "Missing values in 'department' after imputation: 0\n",
      "\n",
      "DataFrame after mode imputation on 'department':\n",
      "   employee_id             name   age department   salary  \\\n",
      "0            1         John Doe  28.0      Sales  55000.0   \n",
      "1            2       Jane Smith  34.0         HR  62000.0   \n",
      "2            3      Bob Johnson   NaN  Marketing  58000.0   \n",
      "3            4   Alice Williams  29.0  Marketing      NaN   \n",
      "4            5      Chris Evans  45.0      Sales  70000.0   \n",
      "5            6      Emily Davis  38.0         HR  67000.0   \n",
      "6            7              NaN  41.0         HR  65000.0   \n",
      "7            8       Mary Clark  30.0      Sales  59000.0   \n",
      "8            9      James Lewis  37.0         HR  62000.0   \n",
      "9           10  Patricia Taylor  32.0         HR  66000.0   \n",
      "\n",
      "                         email  \n",
      "0         john.doe@example.com  \n",
      "1       jane.smith@example.com  \n",
      "2      bob.johnson@example.com  \n",
      "3   alice.williams@example.com  \n",
      "4                          NaN  \n",
      "5      emily.davis@example.com  \n",
      "6    michael.brown@example.com  \n",
      "7       mary.clark@example.com  \n",
      "8      james.lewis@example.com  \n",
      "9  patricia.taylor@example.com  \n"
     ]
    }
   ],
   "source": [
    "# Question: Mode Imputation for Categorical Data\n",
    "# Description: Fill missing values in a categorical column with the mode of that column.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate mode and fill NA: Use mode() to find the most frequent value and fillna() to fill the missing values.\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Sample CSV data as a string (simulate reading from a file)\n",
    "data = \"\"\"\n",
    "employee_id,name,age,department,salary,email\n",
    "1,John Doe,28,Sales,55000,john.doe@example.com\n",
    "2,Jane Smith,34,,62000,jane.smith@example.com\n",
    "3,Bob Johnson,,Marketing,58000,bob.johnson@example.com\n",
    "4,Alice Williams,29,Marketing,,alice.williams@example.com\n",
    "5,Chris Evans,45,Sales,70000,\n",
    "6,Emily Davis,38,HR,67000,emily.davis@example.com\n",
    "7,,41,HR,65000,michael.brown@example.com\n",
    "8,Mary Clark,30,Sales,59000,mary.clark@example.com\n",
    "9,James Lewis,37,,62000,james.lewis@example.com\n",
    "10,Patricia Taylor,32,HR,66000,patricia.taylor@example.com\n",
    "\"\"\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Check the columns and missing values in 'department'\n",
    "print(\"Missing values in 'department' before imputation:\", df['department'].isnull().sum())\n",
    "\n",
    "# Calculate the mode of the 'department' column\n",
    "mode_department = df['department'].mode()[0]\n",
    "print(\"Mode of 'department':\", mode_department)\n",
    "\n",
    "# Fill missing values in 'department' with the mode\n",
    "df['department'].fillna(mode_department, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values in 'department' after imputation:\", df['department'].isnull().sum())\n",
    "print(\"\\nDataFrame after mode imputation on 'department':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'salary' before imputation: 1\n",
      "Median salary: 62000.0\n",
      "Missing values in 'salary' after imputation: 0\n",
      "\n",
      "DataFrame after median imputation on 'salary':\n",
      "   employee_id             name   age department   salary  \\\n",
      "0            1         John Doe  28.0      Sales  55000.0   \n",
      "1            2       Jane Smith  34.0        NaN  62000.0   \n",
      "2            3      Bob Johnson   NaN  Marketing  58000.0   \n",
      "3            4   Alice Williams  29.0  Marketing  62000.0   \n",
      "4            5      Chris Evans  45.0      Sales  70000.0   \n",
      "5            6      Emily Davis  38.0         HR  67000.0   \n",
      "6            7              NaN  41.0         HR  65000.0   \n",
      "7            8       Mary Clark  30.0      Sales  59000.0   \n",
      "8            9      James Lewis  37.0        NaN  62000.0   \n",
      "9           10  Patricia Taylor  32.0         HR  66000.0   \n",
      "\n",
      "                         email  \n",
      "0         john.doe@example.com  \n",
      "1       jane.smith@example.com  \n",
      "2      bob.johnson@example.com  \n",
      "3   alice.williams@example.com  \n",
      "4                          NaN  \n",
      "5      emily.davis@example.com  \n",
      "6    michael.brown@example.com  \n",
      "7       mary.clark@example.com  \n",
      "8      james.lewis@example.com  \n",
      "9  patricia.taylor@example.com  \n"
     ]
    }
   ],
   "source": [
    "# Question: Median Imputation for Skewed Data\n",
    "# Description: Handle missing values in columns with a skewed distribution using the median.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate median and fill NA: Use median() for skewed data and fillna() to handle missing values.\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# CSV data as a string (simulate reading from a file)\n",
    "data = \"\"\"\n",
    "employee_id,name,age,department,salary,email\n",
    "1,John Doe,28,Sales,55000,john.doe@example.com\n",
    "2,Jane Smith,34,,62000,jane.smith@example.com\n",
    "3,Bob Johnson,,Marketing,58000,bob.johnson@example.com\n",
    "4,Alice Williams,29,Marketing,,alice.williams@example.com\n",
    "5,Chris Evans,45,Sales,70000,\n",
    "6,Emily Davis,38,HR,67000,emily.davis@example.com\n",
    "7,,41,HR,65000,michael.brown@example.com\n",
    "8,Mary Clark,30,Sales,59000,mary.clark@example.com\n",
    "9,James Lewis,37,,62000,james.lewis@example.com\n",
    "10,Patricia Taylor,32,HR,66000,patricia.taylor@example.com\n",
    "\"\"\"\n",
    "\n",
    "# Read the data into DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Check missing values before imputation\n",
    "print(\"Missing values in 'salary' before imputation:\", df['salary'].isnull().sum())\n",
    "\n",
    "# Calculate the median of 'salary' column\n",
    "median_salary = df['salary'].median()\n",
    "print(\"Median salary:\", median_salary)\n",
    "\n",
    "# Fill missing values in 'salary' column with median\n",
    "df['salary'].fillna(median_salary, inplace=True)\n",
    "\n",
    "# Check missing values after imputation\n",
    "print(\"Missing values in 'salary' after imputation:\", df['salary'].isnull().sum())\n",
    "\n",
    "print(\"\\nDataFrame after median imputation on 'salary':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after KNN imputation on 'age' and 'salary':\n",
      "   employee_id             name        age department   salary  \\\n",
      "0            1         John Doe  28.000000      Sales  55000.0   \n",
      "1            2       Jane Smith  34.000000        NaN  62000.0   \n",
      "2            3      Bob Johnson  30.666667  Marketing  58000.0   \n",
      "3            4   Alice Williams  29.000000  Marketing  60000.0   \n",
      "4            5      Chris Evans  45.000000      Sales  70000.0   \n",
      "5            6      Emily Davis  38.000000         HR  67000.0   \n",
      "6            7              NaN  41.000000         HR  65000.0   \n",
      "7            8       Mary Clark  30.000000      Sales  59000.0   \n",
      "8            9      James Lewis  37.000000        NaN  62000.0   \n",
      "9           10  Patricia Taylor  32.000000         HR  66000.0   \n",
      "\n",
      "                         email  \n",
      "0         john.doe@example.com  \n",
      "1       jane.smith@example.com  \n",
      "2      bob.johnson@example.com  \n",
      "3   alice.williams@example.com  \n",
      "4                          NaN  \n",
      "5      emily.davis@example.com  \n",
      "6    michael.brown@example.com  \n",
      "7       mary.clark@example.com  \n",
      "8      james.lewis@example.com  \n",
      "9  patricia.taylor@example.com  \n"
     ]
    }
   ],
   "source": [
    "# Question: KNN Imputation\n",
    "# Description: Use K-Nearest Neighbors to impute missing values in a dataset.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Install and import required libraries: Use pip install sklearn if not already installed.\n",
    "# 2. KNN Imputer: Use KNNImputer to fill in missing values.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from io import StringIO\n",
    "\n",
    "# Sample CSV data as string (your dataset)\n",
    "data = \"\"\"\n",
    "employee_id,name,age,department,salary,email\n",
    "1,John Doe,28,Sales,55000,john.doe@example.com\n",
    "2,Jane Smith,34,,62000,jane.smith@example.com\n",
    "3,Bob Johnson,,Marketing,58000,bob.johnson@example.com\n",
    "4,Alice Williams,29,Marketing,,alice.williams@example.com\n",
    "5,Chris Evans,45,Sales,70000,\n",
    "6,Emily Davis,38,HR,67000,emily.davis@example.com\n",
    "7,,41,HR,65000,michael.brown@example.com\n",
    "8,Mary Clark,30,Sales,59000,mary.clark@example.com\n",
    "9,James Lewis,37,,62000,james.lewis@example.com\n",
    "10,Patricia Taylor,32,HR,66000,patricia.taylor@example.com\n",
    "\"\"\"\n",
    "\n",
    "# Read data into DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# For KNN Imputer, we need to use only numeric columns or encode categorical ones\n",
    "# We'll impute 'age' and 'salary' here (numerical columns)\n",
    "\n",
    "# Extract numerical columns for imputation\n",
    "num_cols = ['age', 'salary']\n",
    "df_num = df[num_cols]\n",
    "\n",
    "# Initialize KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Fit and transform the numerical data\n",
    "df_num_imputed = imputer.fit_transform(df_num)\n",
    "\n",
    "# Replace original numerical columns with imputed data\n",
    "df[num_cols] = df_num_imputed\n",
    "\n",
    "print(\"DataFrame after KNN imputation on 'age' and 'salary':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'department': 2\n",
      "Next frequent category to fill missing values: HR\n",
      "\n",
      "DataFrame after imputation:\n",
      "  department\n",
      "0      Sales\n",
      "1  Marketing\n",
      "2      Sales\n",
      "3         HR\n",
      "4         HR\n",
      "5  Marketing\n",
      "6         HR\n",
      "7         HR\n",
      "8      Sales\n",
      "9         HR\n"
     ]
    }
   ],
   "source": [
    "# Question: Detecting and Handling Missing Categorical Data\n",
    "# Description: Detect missing categorical data and handle it by filling with the next frequent category.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Identify missing values in categorical data: Use the isnull() method on categorical columns.\n",
    "# 2. Impute with next frequent category: Use the mode() method to choose the next frequent category.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'department': ['Sales', 'Marketing', 'Sales', 'HR', None, 'Marketing', None, 'HR', 'Sales', 'HR']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Detect missing values\n",
    "print(f\"Missing values in 'department': {df['department'].isnull().sum()}\")\n",
    "\n",
    "# Step 2: Find the next frequent category\n",
    "freq_counts = df['department'].value_counts()\n",
    "second_most_frequent = freq_counts.index[1]\n",
    "\n",
    "print(f\"Next frequent category to fill missing values: {second_most_frequent}\")\n",
    "\n",
    "# Step 3: Fill missing values with next frequent category\n",
    "df['department'].fillna(second_most_frequent, inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after imputation:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Predictive Modeling for Imputation\n",
    "# Description: Use a predictive model to impute missing values for a particular feature using other features.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Partition the data: Split the dataset into train and test based on the presence of missing values.\n",
    "# 2. Train a model: Use a regression model to predict missing values.\n",
    "# 3. Impute missing values with predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after predictive imputation of 'age':\n",
      "     age  salary department\n",
      "0  25.00   50000      Sales\n",
      "1  30.00   60000         HR\n",
      "2  28.00   55000         HR\n",
      "3  35.00   65000      Sales\n",
      "4  40.00   70000         IT\n",
      "5  33.35   62000         IT\n",
      "6  50.00   72000      Sales\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual CSV or DataFrame)\n",
    "data = {\n",
    "    'age': [25, 30, np.nan, 35, 40, np.nan, 50],\n",
    "    'salary': [50000, 60000, 55000, 65000, 70000, 62000, 72000],\n",
    "    'department': ['Sales', 'HR', 'HR', 'Sales', 'IT', 'IT', 'Sales']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Split into train (non-missing age) and test (missing age)\n",
    "train_df = df[df['age'].notnull()]\n",
    "test_df = df[df['age'].isnull()]\n",
    "\n",
    "# Features and target for training\n",
    "X_train = train_df.drop(columns=['age'])\n",
    "y_train = train_df['age']\n",
    "\n",
    "# Features to predict missing ages\n",
    "X_test = test_df.drop(columns=['age'])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Step 2: Create pipeline with preprocessing and model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict missing 'age' values\n",
    "predicted_ages = model.predict(X_test)\n",
    "\n",
    "# Impute the missing values in original dataframe\n",
    "df.loc[df['age'].isnull(), 'age'] = predicted_ages\n",
    "\n",
    "print(\"DataFrame after predictive imputation of 'age':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "        date  value\n",
      "0 2023-01-01   10.0\n",
      "1 2023-01-02    NaN\n",
      "2 2023-01-03    NaN\n",
      "3 2023-01-04   25.0\n",
      "4 2023-01-05    NaN\n",
      "\n",
      "Data after Forward Fill and Backward Fill:\n",
      "        date  value  value_ffill  value_bfill\n",
      "0 2023-01-01   10.0         10.0         10.0\n",
      "1 2023-01-02    NaN         10.0         25.0\n",
      "2 2023-01-03    NaN         10.0         25.0\n",
      "3 2023-01-04   25.0         25.0         25.0\n",
      "4 2023-01-05    NaN         25.0          NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/3405558032.py:29: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['value_ffill'] = df['value'].fillna(method='ffill')\n",
      "/tmp/ipykernel_613/3405558032.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['value_bfill'] = df['value'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Question: Handling Time Series Data with Forward and Backward Fill\n",
    "# Description: Impute missing values in a time series dataset using forward and backward fill methods.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Sort the data: Ensure the dataset is sorted by dates.\n",
    "# 2. Use fillna() with method parameter: Apply ffill() and bfill() for forward and backward fill.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample time series data with missing values\n",
    "data = {\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'value': [10, None, None, 25, None]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'date' column to datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Step 1: Sort the data by date (important for time series)\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2a: Forward fill missing values\n",
    "df['value_ffill'] = df['value'].fillna(method='ffill')\n",
    "\n",
    "# Step 2b: Backward fill missing values\n",
    "df['value_bfill'] = df['value'].fillna(method='bfill')\n",
    "\n",
    "print(\"\\nData after Forward Fill and Backward Fill:\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
