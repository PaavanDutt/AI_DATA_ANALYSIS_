{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Feature Scaling\n",
    "# Task: Explain why feature scaling is essential and demonstrate the impact of unscaled features on a machine learning model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Min-Max Scaling\n",
    "# Task: Implement Min-Max Scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Standardization (Z-score Scaling)\n",
    "# Task: Implement Standardization using Z-score scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 4: Robust Scaling\n",
    "# Task: Implement Robust Scaling to handle outliers in the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 1.0000\n",
      "Accuracy with scaling: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Without scaling\n",
    "model_unscaled = LogisticRegression(max_iter=200)\n",
    "model_unscaled.fit(X_train, y_train)\n",
    "acc_unscaled = model_unscaled.score(X_test, y_test)\n",
    "\n",
    "# With scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model_scaled = LogisticRegression(max_iter=200)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "acc_scaled = model_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Accuracy without scaling: {acc_unscaled:.4f}\")\n",
    "print(f\"Accuracy with scaling: {acc_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            0.428704          0.440556           0.467458   \n",
      "std             0.230018          0.181611           0.299203   \n",
      "min             0.000000          0.000000           0.000000   \n",
      "25%             0.222222          0.333333           0.101695   \n",
      "50%             0.416667          0.416667           0.567797   \n",
      "75%             0.583333          0.541667           0.694915   \n",
      "max             1.000000          1.000000           1.000000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           0.458056  \n",
      "std            0.317599  \n",
      "min            0.000000  \n",
      "25%            0.083333  \n",
      "50%            0.500000  \n",
      "75%            0.708333  \n",
      "max            1.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame for easy visualization\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=iris.feature_names)\n",
    "print(df_scaled.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count       1.500000e+02      1.500000e+02       1.500000e+02   \n",
      "mean       -1.468455e-15     -1.823726e-15      -1.610564e-15   \n",
      "std         1.003350e+00      1.003350e+00       1.003350e+00   \n",
      "min        -1.870024e+00     -2.433947e+00      -1.567576e+00   \n",
      "25%        -9.006812e-01     -5.923730e-01      -1.226552e+00   \n",
      "50%        -5.250608e-02     -1.319795e-01       3.364776e-01   \n",
      "75%         6.745011e-01      5.586108e-01       7.627583e-01   \n",
      "max         2.492019e+00      3.090775e+00       1.785832e+00   \n",
      "\n",
      "       petal width (cm)  \n",
      "count      1.500000e+02  \n",
      "mean      -9.473903e-16  \n",
      "std        1.003350e+00  \n",
      "min       -1.447076e+00  \n",
      "25%       -1.183812e+00  \n",
      "50%        1.325097e-01  \n",
      "75%        7.906707e-01  \n",
      "max        1.712096e+00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "X = iris.data\n",
    "\n",
    "# Apply Standardization\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "df_standardized = pd.DataFrame(X_standardized, columns=iris.feature_names)\n",
    "print(df_standardized.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000       1.500000e+02   \n",
      "mean            0.033333          0.114667      -1.691429e-01   \n",
      "std             0.636974          0.871733       5.043709e-01   \n",
      "min            -1.153846         -2.000000      -9.571429e-01   \n",
      "25%            -0.538462         -0.400000      -7.857143e-01   \n",
      "50%             0.000000          0.000000       1.266348e-16   \n",
      "75%             0.461538          0.600000       2.142857e-01   \n",
      "max             1.615385          2.800000       7.285714e-01   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean          -0.067111  \n",
      "std            0.508158  \n",
      "min           -0.800000  \n",
      "25%           -0.666667  \n",
      "50%            0.000000  \n",
      "75%            0.333333  \n",
      "max            0.800000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Load dataset\n",
    "X = iris.data\n",
    "\n",
    "# Apply Robust Scaling\n",
    "scaler = RobustScaler()\n",
    "X_robust = scaler.fit_transform(X)\n",
    "\n",
    "df_robust = pd.DataFrame(X_robust, columns=iris.feature_names)\n",
    "print(df_robust.describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
