{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Label Encoding vs One-Hot Encoding\n",
    "# Task: Show the difference between Label Encoding and One-Hot Encoding on the Titanic dataset for the 'Sex' feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "# Task: Demonstrate combining Min-Max Scaling and Standardization for the same datasetand explain the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features\n",
    "# Task: Handle multiple categorical features ('Sex', 'Embarked') from the Titanic dataset using One-Hot Encoding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 8: Ordinal Encoding for Ranked Categories\n",
    "# Task: Ordinal encode 'Pclass' (Passenger class) from the Titanic dataset considering passenger class as a ranked feature.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 9: Impact of Scaling on Different Algorithms\n",
    "# Task: Investigate the impact of different scaling techniques on a decision tree model and compare it with a SVM.\n",
    "\n",
    "\n",
    "\n",
    "# Question 10: Custom Transformations for Categorical Features\n",
    "# Task: Implement a custom transformation function for encoding high cardinality categorical features efficiently.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoded Values:\n",
      " 1    577\n",
      "0    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "One-Hot Encoded DataFrame:\n",
      "    Sex_female  Sex_male\n",
      "0         0.0       1.0\n",
      "1         1.0       0.0\n",
      "2         1.0       0.0\n",
      "3         1.0       0.0\n",
      "4         0.0       1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Load Titanic dataset from local CSV\n",
    "titanic = pd.read_csv('/workspaces/AI_DATA_ANALYSIS_/src/Module 3/Hands-on - Data Quality Assessment & Profiling/titanic.csv')\n",
    "\n",
    "# Drop missing values in 'sex' column\n",
    "sex_feature = titanic[['Sex']].dropna()\n",
    "\n",
    "# Label Encoding\n",
    "label_enc = LabelEncoder()\n",
    "sex_label_encoded = label_enc.fit_transform(sex_feature['Sex'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_enc = OneHotEncoder(sparse_output=False)\n",
    "sex_onehot_encoded = onehot_enc.fit_transform(sex_feature)\n",
    "\n",
    "# Display\n",
    "print(\"Label Encoded Values:\\n\", pd.Series(sex_label_encoded).value_counts())\n",
    "print(\"\\nOne-Hot Encoded DataFrame:\\n\", pd.DataFrame(sex_onehot_encoded, columns=onehot_enc.get_feature_names_out(['Sex'])).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0             1             2             3             4  \\\n",
      "count  7.140000e+02  7.140000e+02  7.140000e+02  7.140000e+02  7.140000e+02   \n",
      "mean   1.592253e-16  1.243947e-17 -5.473368e-17 -1.492737e-17  9.454000e-17   \n",
      "std    1.000701e+00  1.000701e+00  1.000701e+00  1.000701e+00  1.000701e+00   \n",
      "min   -1.728532e+00 -8.270201e-01 -1.476364e+00 -2.016979e+00 -5.517031e-01   \n",
      "25%   -8.740804e-01 -8.270201e-01 -1.476364e+00 -6.595416e-01 -5.517031e-01   \n",
      "50%   -1.383587e-02 -8.270201e-01 -2.825656e-01 -1.170488e-01 -5.517031e-01   \n",
      "75%    8.850279e-01  1.209160e+00  9.112324e-01  5.718310e-01  5.245701e-01   \n",
      "max    1.708584e+00  1.209160e+00  9.112324e-01  3.465126e+00  4.829663e+00   \n",
      "\n",
      "                  5             6  \n",
      "count  7.140000e+02  7.140000e+02  \n",
      "mean  -1.990316e-17  4.975789e-18  \n",
      "std    1.000701e+00  1.000701e+00  \n",
      "min   -5.058951e-01 -6.560759e-01  \n",
      "25%   -5.058951e-01 -5.038498e-01  \n",
      "50%   -5.058951e-01 -3.583992e-01  \n",
      "75%    6.668618e-01 -2.495211e-02  \n",
      "max    6.530646e+00  9.032109e+00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Select numeric columns from Titanic dataset\n",
    "numeric_data = titanic.select_dtypes(include='number').dropna()\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "minmax = MinMaxScaler()\n",
    "data_minmax = minmax.fit_transform(numeric_data)\n",
    "\n",
    "# Apply Standardization\n",
    "standard = StandardScaler()\n",
    "data_scaled = standard.fit_transform(data_minmax)\n",
    "\n",
    "# Result: Now data has mean ≈ 0 and std ≈ 1\n",
    "print(pd.DataFrame(data_scaled).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex_male  Embarked_Q  Embarked_S\n",
      "0       1.0         0.0         1.0\n",
      "1       0.0         0.0         0.0\n",
      "2       0.0         0.0         1.0\n",
      "3       0.0         0.0         1.0\n",
      "4       1.0         0.0         1.0\n"
     ]
    }
   ],
   "source": [
    "cat_features = titanic[['Sex', 'Embarked']].dropna()\n",
    "\n",
    "# One-Hot Encode\n",
    "onehot = OneHotEncoder(sparse_output=False, drop='first')  # Drop first to avoid dummy variable trap\n",
    "encoded_cat = onehot.fit_transform(cat_features)\n",
    "\n",
    "# Get feature names\n",
    "encoded_df = pd.DataFrame(encoded_cat, columns=onehot.get_feature_names_out(cat_features.columns))\n",
    "print(encoded_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Pclass_encoded\n",
      "0       3             2.0\n",
      "1       1             0.0\n",
      "2       3             2.0\n",
      "3       1             0.0\n",
      "4       3             2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Only non-null values\n",
    "ordinal_data = titanic[['Pclass']].dropna()\n",
    "\n",
    "# Ordinal Encoding\n",
    "ordinal_enc = OrdinalEncoder()\n",
    "encoded_pclass = ordinal_enc.fit_transform(ordinal_data)\n",
    "\n",
    "# Attach to DataFrame\n",
    "titanic['Pclass_encoded'] = encoded_pclass\n",
    "print(titanic[['Pclass', 'Pclass_encoded']].dropna().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (unscaled): 0.7374\n",
      "SVM (unscaled): 0.6425\n",
      "SVM (scaled): 0.7654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cleaned dataset\n",
    "titanic_clean = titanic[['Pclass', 'Age', 'Fare', 'Sex', 'Survived']].dropna()\n",
    "X = pd.get_dummies(titanic_clean.drop('Survived', axis=1), drop_first=True)\n",
    "y = titanic_clean['Survived']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Without scaling\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "svm_unscaled = SVC().fit(X_train, y_train)\n",
    "\n",
    "# With Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_scaled = SVC().fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Decision Tree (unscaled): {tree.score(X_test, y_test):.4f}\")\n",
    "print(f\"SVM (unscaled): {svm_unscaled.score(X_test, y_test):.4f}\")\n",
    "print(f\"SVM (scaled): {svm_scaled.score(X_test_scaled, y_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Pclass_encoded\n",
      "0       3        0.551066\n",
      "1       1        0.242424\n",
      "2       3        0.551066\n",
      "3       1        0.242424\n",
      "4       3        0.551066\n"
     ]
    }
   ],
   "source": [
    "def frequency_encode(df, column):\n",
    "    freq_map = df[column].value_counts(normalize=True)\n",
    "    return df[column].map(freq_map)\n",
    "\n",
    "# Simulate high-cardinality with 'deck'\n",
    "titanic['Pclass_encoded'] = frequency_encode(titanic.fillna({'Pclass': 'Unknown'}), 'Pclass')\n",
    "print(titanic[['Pclass', 'Pclass_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(titanic.columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
